\chapter{Properties of the two dimensional $\SL_2(F)$}\label{Ch5_PropertiesOfSLOverAlgClosedField}


\section{General Notation}

Throughout this paper, $F$ will denote an arbitrary algebraically closed field. For convenince we let $\SL_2(F)$denote the infinite group $\SL_2(F)$. The letter $p$ will be used to denote the characteristic of $F$. Recall that the characteristic of a field is the smallest number of times which the multilplicative identity of the field, say 1, needs to be summed to reach the additive identity of the field, say 0. If there is no such number, then we regard $p$ as being zero, otherwise it is always a prime. \\
\\
Unless otherwise stated, the letters $\alpha, \beta, \gamma, \delta, \sigma$, and $\sigma$ will denote elements of $F$ and $\delta$ and $\rho$ elements of $F^\times$, where $F^\times$  are the non-zero elements of $F$.

\section{Subsets of $\SL_2(F)$}

In this chapter we make some useful observations about specific elements and subgroups of $L$. We define the following elements of $\SL_2(F)$as follows.

\subsubsection{Special matrices of $\SL_2(F)$}

\begin{definition}[The diagonal matrix of $SL_2(F)$]
\label{SpecialMatrices.d}
\lean{SpecialMatrices.d}
\leanok
    Given an element $\delta \in F^\times$ we define the diagonal matrix:
    \[
    d_\delta = \begin{bmatrix}
        \delta & 0\\
        0 & \delta^{-1}
    \end{bmatrix}
    \]
\end{definition}

\begin{definition}[The shear matrix of $SL_2(F)$]
\label{SpecialMatrices.s}
\lean{SpecialMatrices.s}
\leanok
    Given an element $\delta \in F$ we define the shear matrix:
    \[
    s_\sigma  = \begin{bmatrix}
    1 & 0\\
    \sigma & 1
    \end{bmatrix}
    \]
\end{definition}

We record the nice property of $s_\sigma$

\begin{lemma}[Order of nontrivial $s_\sigma$ ]
\label{SpecialMatrices.order_s_eq_char}
\lean{SpecialMatrices.order_s_eq_char}
\leanok

The order of $s_\sigma$ for $\sigma \ne 0$ is $\textrm{char}(F)$
\end{lemma}
%PROOF AND DEPENDENCIES



\begin{definition}[Rotation by $\pi / 2$ radians matrix]
\label{SpecialMatrices.w}
\lean{SpecialMatrices.w}
\leanok
 We denote the matrix which corresponds to a rotation by $\pi / 2$ radians to be:
 \[
 w = \begin{bmatrix}
    0 & -1\\
    1 & 0
 \end{bmatrix}
 \]
\end{definition}

The matrices $d$, $s$ and $w$ satisfy the following relations:


\begin{lemma}[Closure of $D$ under multiplication]
\label{SpecialMatrices.d_mul_d_eq_d_mul}
\uses{SpecialMatrices.d}
\lean{SpecialMatrices.d_mul_d_eq_d_mul}
\leanok
For any $\delta, \rho \in F^\times$ we have that
\[
d_\delta d_\rho = d_{\delta\rho}
\]
\end{lemma}
\begin{proof}
    We verify by matrix multiplication that indeed:

    \begin{equation*}
        d_\delta d_\rho = \begin{bmatrix} \delta & 0 \\ 0 & \delta^{-1} \end{bmatrix} \begin{bmatrix} \rho & 0 \\ 0 & \rho^{-1} \end{bmatrix} = \begin{bmatrix} \delta \rho & 0 \\ 0 & \delta^{-1} \rho^{-1} \end{bmatrix} = d_{\delta \rho}.
    \end{equation*}
\end{proof}

\begin{lemma}[Closure of $S$ under multiplication]
\label{SpecialMatrices.s_mul_s_eq_s_add}
\uses{SpecialMatrices.s}
\lean{SpecialMatrices.s_mul_s_eq_s_add}
\leanok
    For any $\sigma, \gamma \in F$ we have that
    \[
    s_\sigma s_\gamma = s_{\sigma + \gamma}.
    \]
\end{lemma}
\begin{proof}
    We verify by matrix multiplication that indeed:
\begin{equation*}
    s_\sigma s_\gamma = \begin{bmatrix} 1 & 0 \\ \sigma & 1 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ \gamma & 1 \end{bmatrix} = \begin{bmatrix} 1 & 0 \\ \sigma + \gamma & 1 \end{bmatrix} = s_{\sigma + \gamma}.
\end{equation*}
\end{proof}

\begin{lemma}
\label{SpecialMatrices.d_mul_s_mul_d_inv_eq_s}
\uses{SpecialMatrices.d, SpecialMatrices.s}
\lean{SpecialMatrices.d_mul_s_mul_d_inv_eq_s}
\leanok
    We have that for all $\delta \in F^\times$ and $\sigma \in F$
    \[
    d_\delta s_\sigma d^{-1}_\delta = s_{\sigma \delta^{-2}}.
    \]
\end{lemma}

\begin{proof}
    We verify by matrix multiplication that indeed:

    \begin{equation*}
        d_\delta s_\sigma d^{-1}_\delta = \! \begin{bmatrix} \delta & 0 \\ 0 & \delta^{-1} \end{bmatrix} \begin{bmatrix} 1 & 0 \\ \sigma & 1 \end{bmatrix} \begin{bmatrix} \delta^{-1} & 0 \\ 0 & \delta \end{bmatrix} = \begin{bmatrix} \delta & 0 \\ 0 & \delta^{-1} \end{bmatrix} \! \begin{bmatrix} \delta^{-1} & 0 \\ \sigma \delta^{-1} & \delta \end{bmatrix} \! = \! \begin{bmatrix} 1 & 0 \\ \sigma \delta^{-2} & 1 \end{bmatrix} \! = s_{\sigma \delta^{-2}}.
    \end{equation*}
\end{proof}



\begin{lemma}
\label{SpecialMatrices.w_mul_d_eq_d_inv_w}
\uses{SpecialMatrices.d, SpecialMatrices.w}
\lean{SpecialMatrices.w_mul_d_eq_d_inv_w}
\leanok
For any $\delta \in F^\times$ we have:
\[ 
w d_\delta w^{-1} = d^{-1}_\delta.
\]
\end{lemma}

\begin{proof} 
We verify by matrix multiplication that indeed
\begin{equation*}
w d_\delta w^{-1} = \begin{bmatrix} 0 & 1 \\ - 1 & 0 \end{bmatrix} \begin{bmatrix} \delta & 0 \\ 0 & \delta^{-1} \end{bmatrix} \begin{bmatrix} 0 & - 1 \\ 1 & 0 \end{bmatrix} =  \begin{bmatrix} 0 & 1 \\ - 1 & 0 \end{bmatrix} \begin{bmatrix} 0 & - \delta \\ \delta^{-1} & 0 \end{bmatrix} \! = \! \begin{bmatrix} \delta^{-1} & 0 \\ 0 & \delta \end{bmatrix} \!= d^{-1}_\delta. 
\end{equation*}
\end{proof}

We can now express familiar kinds of matrices of $\SL_2(F)$ in terms of these three matrices:

First we note a straightforward observation:
\begin{remark}
    \label{det_eq_mul_diag_of_lower_triangular}
    \lean{det_eq_mul_diag_of_lower_triangular}
    \leanok
    The determinant of a $2 \times 2$ lower triangular matrix, $M$, is the product of the diagonal entries $\det(M) = M_{11} M_{22}$.
\end{remark}


\begin{remark}
    \label{SpecialLinearGroup.fin_two_diagonal_iff}
    \uses{det_eq_mul_diag_of_lower_triangular}
    \lean{SpecialLinearGroup.fin_two_diagonal_iff}
    \leanok
    A $2 \times 2$ matrix of $\SL_2(F)$, $x$ is a diagonal matrix if and only if $x = d_\delta$ for some $\delta \in F^\times$.
\end{remark}

\begin{remark}
    \label{SpecialLinearGroup.fin_two_shear_iff}
    \uses{SpecialMatrices.s, det_eq_mul_diag_of_lower_triangular}
    \lean{SpecialLinearGroup.fin_two_shear_iff}
    \leanok
    A matrix of $\SL_2(F)$, $x$ is a shear matrix, that is of the form $\begin{bmatrix}
        \alpha & 0\\
        \sigma & \alpha
    \end{bmatrix}$ if and only if either $x = s_\sigma$ or $x = - s_\sigma$ for some $\sigma \in F$.
\end{remark}

\begin{remark}
    \label{SpecialLinearGroup.fin_two_antidiagonal_iff}
    \lean{SpecialLinearGroup.fin_two_antidiagonal_iff}
    \leanok
    A matrix $A \in \SL_2(F)$ is anti-diagonal, that is of the from $\begin{bmatrix}
        0 & \beta\\
        \gamma & 0
    \end{bmatrix}$ if and only if $A = d_\delta w$
    
\end{remark}

From these relations we can now single out the following subgroups of $\SL_2(F)$.

\subsubsection{Special subgroups of $\SL_2(F)$}

\begin{definition}[The subgroup of diagonal matrices]
\label{SpecialSubgroups.D}
\lean{SpecialSubgroups.D}
\leanok
    The set of diagonal matrices with matrix multiplication is a subgroup of $\SL_2(F)$: 
    \[
    D = \{d_\delta \} = \left\{ \begin{bmatrix}\delta & 0\\ 0 & \delta^{-1}\end{bmatrix} \; | \; \delta \in F^\times \right\}
    \]
\end{definition}

\begin{definition}[The subgroup of shear matrices]
\label{SpecialSubgroups.S}
\lean{SpecialSubgroups.S}
\leanok
    The set of shear matrices with matrix multiplication is a subgroup of $\SL_2(F)$:
    \[
    S = \{s_\sigma\} = \left\{\begin{bmatrix}1 & 0\\ \sigma & 1\end{bmatrix} \; | \; \sigma \in F \right\}
    \]
\end{definition}

\begin{definition}[The subgroup of lower triangular matrices]
\label{SpecialSubgroups.L}
\lean{SpecialSubgroups.L}
\leanok
    The set of lower triangular matrices (see \ref{mem_L_iff_lower_triangular}) with matrix multiplication is a subgroup of $\SL_2(F)$
    \[
    L = DS
    \]

    where $DS = \{d_\delta s_\sigma \; | \; \delta \in F^\times \text{ and } \sigma \in F \}$ is the pointwise product of $D$ and $S$.
\end{definition}

\begin{remark}
    \label{mem_L_iff_lower_triangular}
    \uses{SpecialMatrices.d, SpecialMatrices.s}
    \lean{mem_L_iff_lower_triangular}
    \leanok
    The subgroup $L \le \SL_2(F)$ is the subgroup of $2 \times 2$ lower triangular matrices with determinant one, $L =\left\{\begin{bmatrix}
    \alpha & 0\\
    \gamma & \delta
    \end{bmatrix} \; | \; \alpha, \gamma, \delta \in F \text{ and } \alpha \delta = 1 \right\}$.
\end{remark}

%done by Alex
\begin{proof}
    Observe that for every $l \in L$ there is some $\delta \in F^\times$ and $\sigma \in F$ such that $l  = d_\delta s_\sigma = \begin{bmatrix}
        \delta & 0\\
        \sigma * \delta^{-1} & \delta^{-1}
    \end{bmatrix}$ which is lower triangular. 
    
    Furthermore, for every lower triangular matrix $L = \begin{bmatrix}
        \alpha & 0\\
        \gamma & \delta
    \end{bmatrix}$ 
    
    Setting $\delta = \alpha \in F^\times$ as $\alpha \delta = 1$ and setting $\sigma = \gamma \alpha$

    indeed yields the equality

    \[
    d_\delta s_\sigma = \begin{bmatrix}
        \alpha & 0\\
        \gamma & \delta
    \end{bmatrix}
    \]

    Thus $L = D S$ is the set of lower triangular matrices.
\end{proof}

\begin{remark}
    To define the subgroups $D$, $S$ and $L$ in Lean. 
    
    One has to:
    
    \begin{enumerate}
        \item Define what the underlying set is, what is called the \texttt{carrier}.
        \item Prove that the set is closed under multiplication, \texttt{mul_mem'}.
        \item Prove that the set contains the identity element of the group, \texttt{one_mem'}.
        \item Show that the group is closed under the inversion operator $(-)^{-1}$, \texttt{inv_mem'}.
    \end{enumerate}

    Once these four fields have been filled in, one has succesfully defined a subgroup in Lean.
\end{remark}


\begin{remark}
    Despite the definition of $L$ as being $D S$, some work has to be shown that indeed $DS = D \sqcup S$.
    
    If either $D$ or $S$ were normal in $\SL_2(F)$ we would be able to use \texttt{mul_normal} or \texttt{normal_mul}:
    
    \begin{verbatim}
        ∀ {G : Type u_2} [inst : Group G] (N H : Subgroup G) [inst_1 : N.Normal], ↑(N ⊔ H) = ↑N * ↑H
    \end{verbatim}

    However, given neither $D$ or $S$ are normal in $\SL_2(F)$ slightly more work is needed to show this.
    
    It is interesting how Lean really forces either increased understanding or increased frustration.
\end{remark}

Observe that $\SL_2(F)$is the set of all lower triangular matrices in $\SL_2(F)$ whilst $Dw$ is the set of all anti-diagonal matrices.

\begin{equation} \label{Hlowertri} \SL_2(F)= DS =  \{d_\delta s_\sigma\} = \left\{ \begin{bmatrix} \delta & 0 \\ 0 & \delta^{-1} \end{bmatrix} \begin{bmatrix} 1 & 0 \\ \sigma & 1 \end{bmatrix} \right\} = \left\{ \begin{bmatrix} \delta & 0 \\ \sigma \delta^{-1} & \delta^{-1} \end{bmatrix}  \right\}. \end{equation}

\begin{equation} \label{antidiag} Dw = \{ d_\delta w \} =  \left\{  \begin{bmatrix} \delta & 0 \\ 0 & \delta^{-1} \end{bmatrix} \begin{bmatrix} 0 & 1 \\ -1 & 0 \end{bmatrix} \right\} = \left\{ \begin{bmatrix} 0 & \delta \\ -\delta^{-1} & 0 \end{bmatrix}  \right\}. \end{equation}

These elements and subgroups are fundamental to this paper and this notation will be used throughout.

\begin{lemma}[$(D, \cdot) \cong (F^\times, \cdot)$]
\label{SpecialSubgroups.D_iso_units}
\uses{SpecialSubgroups.D, SpecialMatrices.d_mul_d_eq_d_mul}
\lean{SpecialSubgroups.D_iso_units}
\leanok
The map $\psi : F^\times \overset{\sim}{\rightarrow} D$ defined by $\delta \mapsto d_\delta$ defines a group isomorphism.
\end{lemma}

\begin{proof}
    The function $\psi: F^\times \rightarrow D$ defined by $\psi(\delta) = d_\delta$ is a homomorphism between the group $F^\times$ under normal multiplication and $D$ under normal matrix multiplication:
\begin{align*} \psi(\delta \rho) = d_{\delta \rho} =  d_\delta d_\rho = \psi(\delta) \psi(\rho). \tag{by Lemma \ref{6.1}}
\end{align*}
Observe that $\psi$ is trivially injective and surjective and thus an isomorphism. So $D\cong F^\times$ and $D$ is a subgroup of $L$.\\
\end{proof}



\begin{lemma}[ $(S, \cdot) \cong (F, +)$ ]
\label{SpecialSubgroups.S_iso_F, SpecialMatrices.s_mul_s_eq_s_add}
\uses{SpecialSubgroups.S}
\lean{SpecialSubgroups.S_iso_F}
\leanok
    The map $\phi : F \overset{\sim}{\rightarrow} S$ defined by $\sigma \mapsto s_\sigma$ defines a group isomorphism.
\end{lemma}

\begin{proof}
     The function $\phi: F \rightarrow T$ defined by $\phi(\sigma) = s_\sigma$ is a homomorphism between the group $F$ under addition and $S$ under normal matrix multiplication:
\begin{align*} \phi(\sigma + \gamma) = s_{\sigma + \gamma} = s_\sigma s_\gamma = \phi(\sigma) \phi(\gamma). \tag{by Lemma \ref{6.1}}
\end{align*}
It is clear that $\phi$ is injective and surjective and thus an isomorphism. So $ S \cong F$ and $S$ is a subgroup of $L$. \\
\end{proof}



\begin{lemma}
\label{SpecialSubgroups.normal_S_subgroupOf_L}
\lean{SpecialSubgroups.normal_S_subgroupOf_L}
\leanok
$S$ is a normal subgroup of $L$
\end{lemma}

\begin{proof}
    Let $s_\gamma$ and $d_\delta s_\sigma$ be arbitrary elements of $T$ and $H$ respectively. Conjugating $s_\gamma$ by $d_\delta s_\sigma$ gives,
\begin{align*} (d_\delta s_\sigma) s_\gamma (d_\delta s_\sigma)^{-1} &= (d_\delta s_\sigma) s_\gamma (t^{-1}_\sigma d^{-1}_\delta) \\[1.5ex]
&=
d_\delta (s_\sigma s_\gamma t_{-\sigma}) d^{-1}_\delta \qquad \tag{since $t^{-1}_\sigma=t_{-\sigma}$} \\[1.5ex] 
&=
d_\delta s_\gamma d^{-1}_\delta \tag{by Lemma \ref{6.1}} \\[1.5ex] 
&= s_{\gamma \delta^{-2}} \in S. \tag{by Lemma \ref{6.1}}
\end{align*}
Since $s_\gamma$ was chosen arbitrarily from $\SL_2(F)$we have ($d_\delta s_\sigma) S (d_\delta s_\sigma)^{-1} = S$ and since $d_\delta s_\sigma$ was chosen arbitrarily from $L$, we have that $S \vartriangleleft L$. \\
\end{proof}

\begin{remark}[Subgroups of subgroups in Lean]
    In Lean, for this particular scenario, $S$ is considered to be a subgroup of $\SL_2(F)$. 
    
    It is fairly easy to see that $S \not\lhd \SL_2(F)$. When we say that $S \lhd L$, we are implicitly restricting $S$ to be a subset of $L$ and thus we are actually thinking about the subgroup $S \cap L$,
    but in fact this does not change anything becuase $S = S \sqcap L$ as $S \le \SL_2(F)$.

    Informally we do not think twice about this, but when formalizing this we do need to be clear which is the ambient group for $S$ to be normal and in this case it should be a subgroup of $L$, rather than $\SL_2(F)$.
    
    So this is why the informal statement corresponds to the formal statement:

    \begin{verbatim}
    Normal (S F).subgroupOf (L F) 
    \end{verbatim}

    This example highligths how as useful as it is that Lean keeps track of what the ambient groups are, it is often the case that we look at the same object under a different lense such as in this case, where we restrict it to be a 
    subgroup of another group that contains it. It turns out that there is learning curve to becoming comfortable with these transitions.
    On the positive side, the automation leans offers, that is, the tactics and the unification algorithm (the algorithm which allows you to subsitute equal terms when say you use the  \texttt{rw} tactic) is continually being refined, 
    and it is increasingly able to do a lot of coercions on its own.
\end{remark}


\begin{lemma}
\label{SpecialSubgroups.D_join_S_quot_S_subgroupOf_D_join_S_mulEquiv_D_subgroupOf_D_join_S}
\uses{SpecialSubgroups.D, SpecialSubgroups.S, SpecialSubgroups.normal_S_subgroupOf_L}
\lean{SpecialSubgroups.D_join_S_quot_S_subgroupOf_D_join_S_mulEquiv_D_subgroupOf_D_join_S}
\leanok
    $L / S \cong D$.
\end{lemma}

\begin{proof} 
The function $\pi: L \rightarrow D$ defined by $\pi(d_\delta s_\sigma) = d_\delta$ is a homomorphism between $L$ under normal matrix multiplication and $D$ under normal matrix multiplication:
\begin{align*} \pi(d_\delta s_\sigma d_\rho s_\gamma) &= \pi(d_\delta d_\rho s_\sigma s_\gamma) \tag{where $\sigma = \sigma \rho^{2}$ by Lemma \ref{6.1}}
\\ &= d_\delta d_\rho
\\ &= \pi(d_\delta s_\sigma)\pi(d_\rho s_\gamma).
\end{align*}

We see that $\pi$ is trivially surjective and has kernel
\begin{align*}  \ker(\pi) &= \{ d_\delta s_\sigma \in L : \pi(d_\delta s_\sigma) = I_{\SL_2(F)}\} = S.
\end{align*}
Thus by the First Isomorphism Theorem,
\begin{align*} L / \ker(\pi) &\cong \text{Im}(\pi), \\
L / &\cong D.
\end{align*}

\end{proof}

\begin{remark}
Interestingly, this proof was quite hard to formalise for reasons I will expand on below, but first let me introduce some ideas.

There are two complete lattice structures at play here: one where the top element is $\top = \SL_2(F)$ and another lattice which is the corresponding sublattice where $\top = D \sqcup S$.
The second sublattice is crucial because we need $S$ to be normal in an ambient group, and clearly $S \not\lhd \SL_2(F)$; therefore when restricting $S$ to begin a subgroup of $D \sqcup S = L$. Given $S$ is a subgroup of $D \sqcup S = L$ as $S \le S\sqcup D = L$, considered as a subgroup of $D \sqcup S = L$ we as shown in \ref{SpecialSubgroups.normal_S_subgroupOf_{\SL_2(F)}}
it is normal $S$ a subgroup of $L$.

This eventually entails to using the theorem called \texttt{QuotientGroup.quotientInfEquivProdNormalQuotient} which corresponds to the statment

\begin{verbatim}
    H ⧸ N.subgroupOf H ≃* (H ⊔ N) ⧸ N.subgroupOf (H ⊔ N)
\end{verbatim}

Which is in fact the second isomorphism theorem, not the first isomorphism theorem! Which contrasts to how the statement was proved informally.

where in for this particular theorem, \texttt{H} is specialized to:

\begin{verbatim}
    H := (D F).subgroupOf (D F ⊔ S F)
\end{verbatim}

and  \texttt{N} is specialized to:

\begin{verbatim}
    N := (S F).subgroupOf (D F ⊔ S F)
\end{verbatim}

recall that within Lean, \texttt{F} denotes the base field for $\SL_2(F)$, $D$ and $S$.

Written informally, it corresponds to

\[
D \cong \frac{D}{\bot} = \frac{D}{S \sqcap D} \cong \frac{D \sqcup S}{S} = \frac{L}{S}
\]


\end{remark}

\section{The Centre of $\SL_2(F)$}

\begin{definition}
\lean{Subgroup.center}
\leanok
The \textbf{centre} $Z(G)$ of a group $G$ is the set of elements of  $G$ that commute with every element of $G$.
\begin {equation*} Z(G) = \{ z \in G : \forall g \in G, \hspace{6pt} gz=zg \}. \end{equation*}
It is an immediate observation that $Z(G)$ is a normal subgroup of $G$, 
since for each $z \in Z$, $gzg^{-1} = gg^{-1}z = z$, $\forall g \in G$. It's also clear that a group is abelian if and only if $Z(G)=G$.
\end{definition}



\begin{definition}
\label{SpecialSubgroups.Z}
\lean{SpecialSubgroups.Z}
\leanok
    Let $R$ be a commutative ring and define $Z$ to be the subgroup generated by $- I \in \SL_2(R)$
\end{definition}

\begin{remark}
    Observer that the subgroup generated by an element $g \in G$, $\langle g \rangle$, can be thought of more generally within any lattice as the closure of a singleton set ${g}$. Therefore, the subgroup generated by $-I$ is equal to
    
    \[\langle -I \rangle = \overline{\{-1\}} = \inf \{ K \le G \; | \; \{-1\} \subseteq K \}.\]

    When taking the closure of a singleton, when the ambient lattice is the subgroup lattice; and the closure corresponds to taking the powers of the element in the singleton $\{g\}$,
    which is what is typically understood as the subgroup generated by $g$.

    The way $Z$ is defined in Lean is thus:
    \begin{verbatim}
        def Z (R : Type*) [CommRing R] : Subgroup SL(2,R) := closure {(-1 : SL(2,R))}
    \end{verbatim}
\end{remark}

\begin{lemma}
\label{SpecialSubgroups.closure_neg_one_eq}
\lean{SpecialSubgroups.closure_neg_one_eq}
\leanok
The subgroup closure of $\overline{\{-I\}} = \{I, I\}$
\end{lemma}

\begin{lemma}
\label{SpecialSubgroups.center_SL2_eq_Z}
\uses{SpecialSubgroups.Z}% Matrix.SpecialLinearGroup.mem_center_iff}
\lean{SpecialSubgroups.center_SL2_eq_Z}
\leanok
$Z(\SL_2(F)) = \langle - I_{\SL_2(F)}\rangle = Z$.
\end{lemma}

\begin{proof} Take an arbitrary element $x=\begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix} \in \SL_2(F)$and  an arbitrary element $z = \begin{bmatrix} z_1 & z_2 \\ z_3 & z_4 \end{bmatrix} \in Z$ and consider their product:

\begin{align}\label{myeq1} zx = \begin{bmatrix} z_1 & z_2 \\ z_3 & z_4 \end{bmatrix} \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix} &= \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix} \begin{bmatrix} z_1 & z_2 \\ z_3 & z_4 \end{bmatrix} = xz, \nonumber \\[1.5ex]
\begin{bmatrix} z_1 \alpha + z_2 \gamma & z_1 \beta + z_2 \delta \\ z_3 \alpha + z_4 \gamma & z_3 \beta + z_4 \delta \end{bmatrix} &= \begin{bmatrix} z_1 \alpha + z_3 \beta & z_2 \alpha + z_4 \beta \\ z_1 \gamma + z_3 \delta & z_2 \gamma + z_4 \delta \end{bmatrix}.
\end{align}

\noindent Equating either the top left or bottom right entries, we see that $z_2 \gamma = z_3 \beta$. Since $\beta$ and $\gamma$ can take any values in $F$, for equality to always hold we must have $z_2 = 0 = z_3$. Hence equation (\ref{myeq1}) simplifies to

\begin{equation*} \begin{bmatrix} z_1 \alpha & z_1 \beta \\ z_4 \gamma & z_4 \delta \end{bmatrix} = \begin{bmatrix} z_1 \alpha & z_4 \beta \\ z_1 \gamma & z_4 \delta \end{bmatrix}. \end{equation*}

Thus 
\begin{equation*} 
    z_1 = z_4 \qquad  \text{and} \qquad z =  
    \begin{bmatrix} z_1 & 0 \\ 0 & z_1 \end{bmatrix}. 
\end{equation*}
Since we are working in the special linear group, det$(z)=1$, thus $z_1 = \pm 1$ and $Z = \langle - I_{\SL_2(F)}\rangle$ as required. Observe that this is a cyclic group of order 2 except in the case of $p = 2$ where $- I_{\SL_2(F)} = I_{\SL_2(F)}$. \\
\end{proof}

Following this result, for ease of notation, $Z(\SL_2(F))$ will be denoted simply by $Z$ throughout the rest of this paper.

\begin{lemma}
\label{SpecialSubgroups.exists_unique_orderOf_eq_two}
\lean{SpecialSubgroups.exists_unique_orderOf_eq_two}
\leanok
    If $p\neq 2$, then $\SL_2(F)$ contains a unique element of order 2. \\
\end{lemma}

\begin{proof} 
Consider an arbitrary element $x \in \SL_2(F)$with order 2. That is $x^2 = I_{\SL_2(F)}$, $x \neq I_{\SL_2(F)}$and thus $x=x^{-1}$.
\begin{equation*} 
    x = \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix} = \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix}^{-1} = \begin{bmatrix} \delta & - \beta \\ - \gamma & \alpha \end{bmatrix}.
\end{equation*}
\noindent Thus $\alpha = \delta$, $\beta = - \beta \Rightarrow 2\beta = 0$ and $\gamma = - \gamma \Rightarrow 2\gamma = 0$. In the case of $p \neq 2$ this gives $\beta = 0 = \gamma$. So
\begin{equation*} 
    x = \begin{bmatrix} \alpha & 0 \\ 0 & \alpha \end{bmatrix}.
\end{equation*}
\noindent Also $\alpha^2 = 1$ since $x \in$ $\SL_2(F)$, so $\alpha = \pm 1$. For $x$ to have order 2, we must have $\alpha = - 1$. Hence there is a unique element of order 2, namely $- I_{\SL_2(F)}$.
\\
\end{proof}

\begin{lemma}
    \label{SpecialSubgroups.card_Z_eq_two_of_two_ne_zero}
    \lean{SpecialSubgroups.card_Z_eq_two_of_two_ne_zero}
    \leanok
    If the characteristic $\textrm{char}(F) \ne 2$ then $|Z| = 2$.
\end{lemma}
\begin{proof}
    If $\textrm{char}(F) \ne 2$ then $1 \ne -1$ as $2 \ne 0$ therefore, $I \ne -I$ which shows that $Z = \{I , -I\}$ contains two distinct elements.
\end{proof}

\begin{lemma}
    \label{SpecialSubgroups.card_Z_eq_one_of_two_eq_zero}
    \lean{SpecialSubgroups.card_Z_eq_one_of_two_eq_zero}
    \leanok
    If the characteristic $\textrm{char}(F) = 2$ then $|Z| = 1$. 
\end{lemma}
\begin{proof}
    If $\textrm{char}(F) = 2$ then $1 = -1$ as $2 = 0$ therefore, $I = -I$ which shows that $Z = \{I , -I\} = \{I\}$ only contains one element.
\end{proof}

\begin{lemma}[$Z$ is cyclic]
    \label{SpecialSubgroups.IsCyclic_Z}
    \lean{SpecialSubgroups.IsCyclic_Z}
    \leanok
\end{lemma}
\begin{proof}
    By construction, $Z = \overline{\{-I\}} = \{-I^k \; | \; k \in \Z \} = \langle -I \rangle$, therefore $Z$ is generated by a single element and is thus cyclic.
\end{proof}


In the next chapter it will be useful to record the interactions between $S$ and $Z$ for instance

\begin{definition}
    \label{SpecialSubgroups.SZ}
    \uses{SpecialSubgroups.S, SpecialSubgroups.Z, SpecialMatrices.s_mul_s_eq_s_add}
    \lean{SpecialSubgroups.SZ}
    \leanok
    We define the subgroup $SZ$ to be the subgroup with the underlying set $S \cup -S$, or equivalently the pointwise product $SZ$.
\end{definition}

\begin{remark}
\label{SpecialSubgroups.S_mul_Z_subset_SZ}
\uses{SpecialSubgroups.SZ}
\lean{SpecialSubgroups.S_mul_Z_subset_SZ}
$SZ = S \cup -S$
\leanok
\end{remark}

\begin{lemma}
    \label{SpecialSubgroups.S_join_Z_eq_SZ}
    \uses{SpecialSubgroups.Z, SpecialSubgroups.S, SpecialSubgroups.closure_neg_one_eq, SpecialSubgroups.S_mul_Z_subset_SZ}
    \lean{SpecialSubgroups.S_join_Z_eq_SZ}
    \leanok
    The join of subgroups $S \sqcup Z = SZ$
\end{lemma}
% PROOF AND DEPENDENCIES

\section{Conjugacy of the Elements of $\SL_2(F)$}

\subsubsection{Classification of elements of $\SL_2(F)$ up to conjugation}

\begin{lemma}[Upper triangularizability criteria]
\label{isConj_upper_triangular_iff}
\lean{isConj_upper_triagnular_iff}
\leanok
    A matrix $M \in \textrm{Mat}_2(F)$ is triangularizable if and only if there exists an invertible matrix $C \in \GL_2(F)$ such that the bottom left entry
    $C M C^{-1}_{21} = 0$.
\end{lemma}

\begin{proof}
    Given a matrix $U$ is in upper triangular form if and only if
    \[
    U = \begin{bmatrix}
    a & b\\
    0 & d
    \end{bmatrix}
    \]
    
    that is, the bottom left entry is zero. It then follows that 

    $M$ is triangularizable if and only there exists a $C \in \GL_2(F)$ such that is in upper triangular form $C M C^{-1}$, that is, the bottom left entry of $C M C^{-1}$ is zero. 
\end{proof}

\begin{lemma}[(Upper) triangularizability of a $2 \times 2$ matrix over an algebraically closed field]
\label{isTriangularizable_of_algClosed}
\uses{isConj_upper_triangular_iff}
\lean{isTriangularizable_of_algClosed}
\leanok
    When $F$ is an algebraically closed field, 
    for any $M \in \textrm{Mat}_2(F)$ there exists an invertible matrix $C \in \SL_2(F) \le \GL_2(F)$ such that $C M C^{-1} = U$ where
    \[
    U = \begin{bmatrix}
        a & b\\
        0 & d
    \end{bmatrix}\] for some $a, b, d \in F$.

\end{lemma}

\begin{proof}
We prove this by direct computation. 

Let 

\[
M = \begin{bmatrix}
\alpha & \beta\\
\gamma & \delta
\end{bmatrix} \in \textrm{Mat}_2(F)
\]

By lemma \ref{isConj_upper_triangular_iff}, we only need to show that we can find a matrix $C \in \SL_2(F)$ such that when it acts on $M$ by conjugation, the bottom left entry is annihilated.

\begin{itemize}
    \item Suppose on the one hand that $\beta \ne 0$
    
    Observe that 
    
    \begin{equation}\label{triang}
        s_\sigma M s_\sigma^{-1} = \left(\begin{bmatrix}
            -\beta \sigma + \alpha & \beta \\
            -\beta \sigma^{2} + \alpha \sigma - \delta \sigma + \gamma & \beta \sigma + \delta
            \end{bmatrix}\right)
    \end{equation}

    Given $F$ is algebraically closed we can set $\sigma \in F$ to be a root of the polynomial

    \[
    P(X) := -\beta X^{2} + \alpha X - \delta X + \gamma 
    \]

    setting $C := s_\sigma$ yields the desired element which triangularizes $M$.
    

    \item Suppose on the other hand that $\beta = 0$
    
    Given the top right entry is zero we only need find a matrix in $\SL_2(F)$ which flips the antidiagonal entries (modulo modifying the signs)
    it is thus sufficient to use 
        \[
        w = \begin{bmatrix}
        0 & -1\\
        1 & 0
        \end{bmatrix} \quad \text{as indeed} \quad w M w^{-1} = \begin{bmatrix}
            \delta & -\gamma\\
            0 & \alpha
        \end{bmatrix} \text{ is in triangular form} 
        \]
\end{itemize}

\end{proof}

\begin{remark}[Upper triangular matrices are conjugate to lower triangular matrices]
    \label{lower_triangular_isConj_upper_triangular}
    \uses{SpecialMatrices.w}
    \lean{lower_triangular_isConj_upper_triangular}
    \leanok
    For every $U \in \textrm{Mat}_2(F)$ that is upper triangular the matrix $w U w^{-1}$ is a lower triangular matrix
\end{remark}

\begin{lemma}
    \label{upper_triangular_isConj_diagonal_of_nonzero_det}
    \lean{upper_triangular_isConj_diagonal_of_nonzero_det}
    \leanok
    An upper triangular matrix $U = \begin{bmatrix}
        \alpha & \beta\\
        0 & \delta
    \end{bmatrix}$ is conjugate to a diagonal matrix if $\alpha - \delta \ne 0$
\end{lemma}

\begin{proof}
We show this by direct computation.

Conjugation of $M$ by the matrix 

\[
C := \begin{bmatrix}
    1 & \frac{\beta}{\alpha - \delta}\\
    0 & 1
\end{bmatrix}
\]

yields a diagonal matrix (see the Lean code for the computation!).
\end{proof}


\begin{proposition}
\label{SL2_IsConj_d_or_IsConj_s_or_IsConj_neg_s_of_AlgClosed}
\uses{isTriangularizable_of_algClosed, lower_triangular_isConj_upper_triangular, upper_triangular_isConj_diagonal_of_nonzero_det}
\lean{SL2_IsConj_d_or_IsConj_s_or_IsConj_neg_s_of_AlgClosed}
\leanok
    Each element of $\SL_2(F)$ is conjugate to either $d_\delta$ for some $\delta \in F^\times$, or to $\pm s_\sigma$ for some $\sigma \in F$.
\end{proposition}

\begin{proof} Since $F$ is algebraically closed, any element $x \in \SL_2(F)$can be regarded as a linear transformation in the 2 dimensional vector space over $F$, with the eigenvalues $\pi_1$ and $\pi_2$. \\
\\
\space If $\pi_1$ and $\pi_2$ are distinct, then $x$ is thus diagonalisable. That is, there exists an invertible matrix $a \in GL(2, F)$ such that $y = axa^{-1}$ is a diagonal matrix. Furthermore, we can multiply $a$ by a suitable scalar to find an element in $\SL_2(F)$which conjugates $x$ and $y$:

\begin{align*}
    \text{Set} \; b = \frac{a}{\sqrt {\text{det}(a)}}, \quad \text{thus } \; bxb^{-1} =\frac{a}{\sqrt {\text{det}(a)}} \; x \; (\sqrt{\text{det}(a)} \; )\,a^{-1} = axa^{-1} = y.
\end{align*}

Observe that det$(b)=1$, hence $x$ and $y$ are conjugate in $L$. Furthermore, since $y$ is a diagonal matrix it must belong to the set $D$, showing that $x$ is conjugate to $d_\delta$ for some $\delta \in F^\times$. \\
\\
\space If $\pi_1 = \pi_2$ then $x$ has just one repeated eigenvalue. Suppose that $x$ is diagonalisable. Then there exists an element $c \in GL(2, F)$ and a diagonal matrix $\pi_1 I_G$ such that $x = c(\pi_1 I_G)c^{-1} = \pi_1 I_G$. Thus $x = \pm I_G$, which trivially belongs to both $D$ and $\times Z$. \\
\\
Now assume that $x$ is not diagonalisable. Chapter 7 of \cite{matrix} shows that there exists an element $d \in GL(2, F)$, such that $x= djd^{-1}$, where, $$j = \begin{bmatrix} \pi_1 & 1 \\ 0 & \pi_1 \end{bmatrix}$$ is the Jordan Normal Form of $x$. By the method described above, we can multiply $d$ by a suitable scalar to show that $x$ is conjugate to $j$ in $L$. Now we conjugate $j$ by an element of $\SL_2(F)$whose top left entry is 0.

\begin{align*}
    \begin{bmatrix} 0 & -\gamma^{-1} \\ \gamma & \delta \end{bmatrix} \begin{bmatrix} \pi_1 & 1 \\ 0 & \pi_1 \end{bmatrix} \begin{bmatrix} \delta & \gamma^{-1} \\ -\gamma & 0 \end{bmatrix} = \begin{bmatrix} 0 & -\gamma^{-1} \\ \gamma & \delta \end{bmatrix} \begin{bmatrix} \pi_1 \delta - \gamma & \pi_1 \gamma^{-1} \\ -\pi_1 \gamma & 0 \end{bmatrix} = \begin{bmatrix} \pi_1 & 0 \\ -\gamma^{2} & \pi_1 \end{bmatrix}
\end{align*}
\\
Now clearly the determinant of $x$ is equal to the determinant of $j$, namely 1, which means that $\pi_1 = \pm 1$. This shows that $j$ is conjugate in $\SL_2(F)$to some element in $\times Z$ as well as $x$. Furthermore, since conjugation is transitive, $x$ is conjugate to $\pm s_\sigma$ for some $\sigma \in F$.

\end{proof}

\begin{remark}

This was the first tedious proof to formalise in Lean.

Given the (informal) proof presented of propostion \ref{SL2_IsConj_d_or_IsConj_s_or_IsConj_neg_s_of_AlgClosed} extracted from Christopher Butler's exposition uses the Jordan Normal Form theorem. 

Furtrmore, since at the time of writing, the Jordan Normal form theorem is still not yet in Mathlib this theorem turned out to be quite difficult to formalise.

Ultimately, I initially set out to prove the Jordan Normal Form theorem for $2 \times 2$ matrices by studying the eigenspace and generalized eigenspaces of the endomorphism associated to a $2 \times 2$ matrix - It turned out to be much more effort and did not manage to complete it. 
Eventually I understood that I might have well formalised the general theorem and furthemore, understood why the theorem is not yet in mathlib; and more in general, it is clear to me why certain "standard" results are not in Mathlib. 
The crux always lies at finding the right abstraction, in this particular case, is it best to prove the theorem for matrices or for endomoprhism? what will be the easiest approach which is most general and useful (!).
The reason why the Jordan Normal Form theorem is not yet in Mathlib is because it hinges on the following two results which have not been formalised yet:

\begin{enumerate}
    \item The classification of nilpotent endomorphisms.
    \item The classification of semisimple endomorphisms.
\end{enumerate}

Such formalization would be an amazing project to undertake. Bear in mind, the theorem formalized is the more general Jordan-Chevallier theorem.

To my understanding, the general theorem will be formalised by studying the eigenspace and general eigenspace. This approach turned out to be essentially equivalent in difficuly to the way I was initially formalising the special case of $2 \times 2$ matrices over an algebraically closed field.

Therefore, given my task has a fair amount of constraints, namely, my task being the Jordan Normal Form restricted to $2 \times 2$ matrices over an algebraically closed field with determinant one. I eventually heeded Prof. Kevin Buzzard's advice of making my life easy, and classify matrices up to conjugation 
by finding the suitable matrices by which to conjugate to put them in either the form of $d_\delta$ or $\pm s_\sigma$.
\end{remark}

\section{Centralisers \& Normalisers}

Both the centraliser and normaliser of a subset $H$ are subgroups of $G$. Note also that the centraliser is a stronger condition than the normaliser and any element in the centraliser of $H$ is also in its normaliser. If $H$ is a singleton then it's clear that its centraliser and normaliser are equal.\\

\subsubsection{Normalisers}

\begin{definition}
\lean{Subgroup.normalizer}
\leanok
The \textbf{normaliser} $N_G(H)$ of a subset $H$ of a group $G$ is the set of elements of $G$ which stabilise $H$ under conjugation.
\begin{equation*} N_G(H) = \{ g \in G : gHg^{-1}=H\}. \end{equation*}
\end{definition}


\begin{remark}
    \label{lower_triangular_iff_top_right_entry_eq_zero}
    \lean{lower_triangular_iff_top_right_entry_eq_zero}
    \leanok
    A matrix $M \in \textrm{Mat}(2; F)$ is lower triangular if and only if the $M_{12} = 0$.
\end{remark}

\begin{proposition}[Normalizer of subgroups of $S$ are contained in $L$]
\label{normalizer_subgroup_S_le_L}
\uses{mem_L_iff_lower_triangular, lower_triangular_iff_top_right_entry_eq_zero}
\lean{normalizer_subgroup_S_le_L}
\leanok
 For any subgroup $S_0 \leq S$ with order greater than 1, we have that the normalizer $N_{\SL_2(F)}(S_0) \subset L$.
\end{proposition}

\begin{proof}
Let $s_\sigma$ be an arbitary element of $S_0$ with $\sigma \neq 0$. To determine the normaliser of $S_0$ in $\SL_2(F)$we consider which $x \in \SL_2(F)$ satisfy $x s_\sigma x^{-1} \in S_0$.
\begin{align*} x s_\sigma x^{-1} &= \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix} \begin{bmatrix} 1 & 0 \\ \sigma & 1 \end{bmatrix} \begin{bmatrix} \delta & - \beta \\ - \gamma & \alpha \end{bmatrix}
\\[1.5ex] &= \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix} \begin{bmatrix} \delta & - \beta \\ \delta \sigma - \gamma & \alpha - \beta \sigma \end{bmatrix}
\\[1.5ex] &= \begin{bmatrix} \alpha \delta - \beta \gamma + \beta \delta \sigma & - \beta^2  \sigma \\ \delta^2 \sigma & \alpha \delta - \beta \gamma - \beta \delta \sigma \end{bmatrix}.
\end{align*}
Since $x s_\sigma x^{-1} \in S_0$ we have $- \beta^2  \sigma = 0$ and since $\sigma \neq 0$, we have $\beta = 0$. Since $s_\sigma$ was chosen arbitrarily, any element which normalises $S_0$ is a lower diagonal matrix and is therefore in $H$ by (\ref{Hlowertri}). Thus $N_{\SL_2(F)}(S_0) \subset H$ as required. \\
\end{proof}

\begin{lemma}
    \label{ex_of_card_D_gt_two}
    \lean{ex_of_card_D_gt_two}
    \leanok
    If the cardinality of finite subgroup of $D_0 \le D$ is greater than $2$ then there exists an element $x \in D_0$ which does not belong to the center $Z$, that is, $x \ne d_1 \ne I$ and $x \ne d_{-1} = -I$.
\end{lemma}
\begin{proof}
 Suppose for a contradiction that if $\delta \ne \pm 1$ then $d_\delta \notin D_0$. We show that $D_0 \le Z$ and therefore, $|D_0| \le 2$ our contradiction.
 
 Let $d_\delta \in D_0 \le D$ then given $d_\delta \notin D_0$ if $\delta \ne \pm 1$ and $Z = \langle -I\rangle = \{I, -I\}$. It immediately follows that $D_0 \le Z$.

\end{proof}

\begin{proposition}[Normalizers of subgroups of $D$ are contained in $L$]
\label{normalizer_subgroup_D_eq_DW}
\uses{SpecialLinearGroup.fin_two_diagonal_iff, SpecialLinearGroup.fin_two_antidiagonal_iff, ex_of_card_D_gt_two}
\lean{normalizer_subgroup_D_eq_DW}
\leanok
    $N_{\SL_2(F)}(D_0) = \langle D , w \rangle$, where  $D_0$ is any subgroup of $D$ with order greater than 2. \\
    \end{proposition}
    
    \begin{proof} Since $|D_0| > 3$, we can choose a $d_\delta \in D_0 \! \setminus \! Z$, that is where $\delta \neq 1$. To determine the normaliser of $D_0$ in $\SL_2(F)$we consider which $x \in \SL_2(F)$satisfy $x d_\delta x^{-1} \in D_0$.
        \begin{align}\label{6.3proof3} xd_\delta x^{-1} &= \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix} \begin{bmatrix} \delta & 0 \\ 0 & \delta^{-1} \end{bmatrix} \begin{bmatrix} \delta & - \beta \\ - \gamma & \alpha \end{bmatrix} \nonumber \\[1.5ex]
        &= \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix} \begin{bmatrix} \delta \delta & - \beta \delta \\ - \gamma \delta^{-1} & \alpha \delta^{-1} \end{bmatrix} \nonumber \\[1.5ex]
        &= \begin{bmatrix} \alpha \delta \delta - \beta \gamma \delta^{-1} & \alpha \beta (\delta^{-1} - \delta) \\ \gamma \delta (\delta - \delta^{-1}) & \alpha \delta \delta^{-1} - \beta \gamma \delta \end{bmatrix} \in D_0.
        \end{align}
        
        Since (\ref{6.3proof3}) is in $D_0$, the top right and bottom left entries must be 0. Since  $\delta \neq \pm 1$, we have $\delta \neq \delta^{-1}$ and so $\alpha \beta = 0 = \gamma \delta$. \\
        \\
         \space If $\alpha = 0$, then $\beta$ and $\gamma$ are non-zero since det$(x) = 1$, thus $\delta = 0$. So det$(x) = - \gamma \beta = 1$  and $- \gamma = \beta^{-1}$. (\ref{6.3proof3}) becomes $$\begin{bmatrix} \delta^{-1} & 0 \\ 0 & \delta \end{bmatrix} = d^{-1}_\delta.$$Since $D_0$ is a group, it contains the inverse of each of it's elements, so $d^{-1}_\delta \in D_0$ as required. In this case we have $x \in wD$. \\
        \\
         \space If $\alpha \neq 0$, then similarly $\beta = 0$, $\delta = \alpha^{-1}$ and $\gamma = 0$. (\ref{6.3proof3}) now becomes $$\begin{bmatrix} \delta & 0 \\ 0 & \delta^{-1} \end{bmatrix} = d_\delta \in D_0.$$This time we have $x \in D$. So $x \in D \cup wD = \langle D , w \rangle$ and any element which normalises $D_0$ is in $\langle D , w \rangle$, thus $N_{\SL_2(F)}(D_0) \subset \langle D , w \rangle$. \\
        \\
        Now take an arbitrary $y \in \langle D , w \rangle = D \cup wD$. If $y \in D$ then $y = d_{\rho 1}$, for some $\rho 1 \in F^\times$.
        \begin{align*} d_{\rho 1} d_\delta d^{-1}_{\rho 1} = d_\delta \in D_0. \tag{by Lemma \ref{6.1}}
        \end{align*}
        
        If $y \in wD$ then $y = w d_{\rho 2}$, for some $ d_{\rho 2} \in F^\times$.
        \begin{align*} (w d_{\rho 2}) d_\delta (w d_{\rho 2})^{-1} &= w d_{\rho 2} d_\delta d^{-1}_{\rho 2} w^{-1}
        \\ &= w d_\delta w^{-1}
        \\ &= d^{-1}_\delta \in D_0 \tag{by Lemma \ref{6.1}}.
        \end{align*}
        
        Thus $y$ indeed who whole of $\langle D , w \rangle$ is contained in $N_{\SL_2(F)}(D_0)$. This inclusion gives the desired result, $N_{\SL_2(F)}(D_0) = \langle D , w \rangle$. \\
        
        \end{proof}

%-----------------------------

\subsubsection{Centralisers}

\begin{definition}[Centralizer]
\lean{Subgroup.centralizer}
\leanok
The \textbf{centraliser} $C_G(H)$ of a subset $H$ of a group $G$ is the set of elements of $G$ which commute with each element of $H$.
\begin{equation*} 
    C_G(H) = \{ g \in G  : gh=hg, \quad \forall h\in L \}. \end{equation*} 
\end{definition}

\begin{remark}
    \label{centralizer_neg_eq_centralizer}
    \lean{centralizer_neg_eq_centralizer}
    \leanok
     Let $G$ be a group with the negation operator $-(\; \cdot \;)$, the centralizer of an element equals the centralizer of the negative of the element, that is, $C_G(x) = C_G(-x)$
\end{remark}
    

    
    
    \begin{proposition}[Centralizer of noncenter $s_\sigma$]
    \label{centralizer_s_eq_SZ}
    \uses{SpecialLinearGroup.fin_two_shear_iff, centralizer_neg_eq_centralizer, SpecialSubgroups.S, SpecialSubgroups.Z, SpecialMatrices.s}
    \lean{centralizer_s_eq_SZ}
    \leanok
    The centralizer $C_{\SL_2(F)}(\pm s_\sigma) =  S \times Z $ where $\sigma \neq 0$.
    \end{proposition}
    
    \begin{proof}
    To determine the centraliser of $s_\sigma$ in $L$, we consider which $y \in \SL_2(F)$satisfy $y s_\sigma = s_\sigma y$ for an arbitrarily chosen $s_\sigma$, with $\sigma \neq 0$. \\
    \vspace{-0.5mm}
    \begin{align}\label{6.3proof2} y s_\sigma &= s_\sigma y, \nonumber \\[1.5ex]
    \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix} \begin{bmatrix} 1 & 0 \\ \sigma & 1 \end{bmatrix} &= \begin{bmatrix} 1 & 0 \\ \sigma & 1 \end{bmatrix} \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix}, \nonumber \\[1.5ex]
    \begin{bmatrix} \alpha + \beta \sigma & \beta \\ \gamma + \delta \sigma & \delta \end{bmatrix} &= \begin{bmatrix} \alpha & \beta \\ \gamma +  \alpha \sigma & \delta + \beta \sigma \end{bmatrix}.
    \end{align}
    \vspace{.5mm}
    
    Equating the top left entries of (\ref{6.3proof2}) gives $\alpha + \beta \sigma = \alpha$ which means $\beta = 0$ since $\sigma \neq 0$ by assumption. Equating the bottom left entries gives that $\alpha = \delta$. Finally, since det$(y) = 1$, we have $\alpha \delta = 1$ so $\alpha = \pm 1$. Thus a $y \in C_{\SL_2(F)}(s_\sigma)$ is
    
    \begin{align*} y &= \begin{bmatrix} \alpha & 0 \\ \gamma & \alpha \end{bmatrix}. \tag{where $\alpha = \pm 1$}
    \end{align*}
    
    So $y = \pm s_\sigma$ for some $\sigma \in F$, and $SZ = \{ \pm s_\sigma \} \subset C_{\SL_2(F)}(s_\sigma)$. Now take an arbitrary $s_\gamma z \in SZ$.
    \begin{align*} (s_\gamma z) s_\sigma &= s_\sigma (s_\gamma z),
    \\ s_\gamma s_\sigma z &= s_\sigma s_\gamma z, \tag{since $z \in Z$}
    \\ t_{\gamma + \sigma} &= t_{\gamma + \sigma}.
    \end{align*}
    
    Thus $s_\gamma z$ and indeed the whole of $SZ$ is contained in $ C_{\SL_2(F)}(s_\sigma)$, so $C_{\SL_2(F)}(s_\sigma) = SZ$. \\
    \\
    Since $S$ commutes elementwise with $Z$ and $\cap Z = \{ I_G \}$, we can apply Corollary \ref{directproductZ} and assert that $C_{\SL_2(F)}(s_\sigma) = SZ \cong S \times Z$ as required. The centraliser of $- s_\sigma$ is also $\times Z$, since an element $x$ commutes with $- s_\sigma$ if and only if it commutes with $s_\sigma$:
    \begin{align*} 
        xs_\sigma = s_\sigma x \iff -(x s_\sigma) = - (s_\sigma x) \iff x(- s_\sigma) = (- s_\sigma)x.
    \end{align*}
    
    Note that in case of $\sigma = 0$, $\pm s_\sigma \in Z$ and thus it's centraliser is the whole of $L$.
    
    \end{proof}

    

    \begin{proposition}[Centralizer of noncenter $d_\delta$]
        \label{centralizer_d_eq_D}
        \uses{SpecialMatrices.d, SpecialLinearGroup.fin_two_diagonal_iff, SpecialSubgroups.D}
        \lean{centralizer_d_eq_D}
        \leanok

        The centralizer $C_{\SL_2(F)}(d_\delta) = D$ for $\delta \neq \pm 1$.
        \end{proposition}
        
        
        \begin{proof}
        Now we consider which $y \in \SL_2(F)$satisfy $y d_\delta = d_\delta y$ for an arbitrarily chosen $d_\delta$, with $\delta \neq \pm 1$.
        \begin{align}\label{6.3proof4} y d_ \delta &= d_\sigma y, \nonumber \\[1.5ex]
        \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix} \begin{bmatrix} \delta & 0 \\ 0 & \delta^{-1} \end{bmatrix} &= \begin{bmatrix} \delta & 0 \\ 0 & \delta^{-1} \end{bmatrix} \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix}, \nonumber \\[1.5ex]
        \begin{bmatrix} \alpha \delta & \beta \delta^{-1} \\ \gamma \delta & \delta \delta^{-1} \end{bmatrix} &= \begin{bmatrix} \alpha \delta & \beta \delta \\ \gamma \delta^{-1} & \delta \delta^{-1} \end{bmatrix}.
        \end{align}
        
        Equating the top right and bottom left entries of (\ref{6.3proof4}) gives that $\beta = 0 = \gamma$ since Since $\delta \neq \delta^{-1}$. Thus $\delta = \alpha^{-1}$ and 
        \begin{align*} x = \begin{bmatrix} \alpha & 0 \\ 0 & \alpha^{-1} \end{bmatrix} \in D. 
        \end{align*}
        
        Thus $x$ and indeed the whole of $C_{\SL_2(F)}(d_\delta)$ is contained in $D$. Now take an arbitrary $d_\rho \in D$.
        \begin{align*} d_\rho d_\delta = d_{\rho \delta} = d_\delta d_\rho.
        \end{align*}
        So clearly $D \subset C_{\SL_2(F)}(d_\delta)$ and thus $C_{\SL_2(F)}(d_\delta) = D$ as required.
        \end{proof}

%---------------------------------------------------


\begin{proposition}[Centralizers of conjugate elements]
    \label{conjugate_centralizers_of_IsConj}
    \lean{conjugate_centralizers_of_IsConj}
    \leanok
    Let $a$ and $b$ be conjugate elements in a group $G$. Then $\exists \, x \in G$ such that $xC_G(a)x^{-1} = C_G(b)$. \vspace{3mm}
\end{proposition}

\begin{proof}
This proposition essentially claims that conjugate elements have conjugate centralisers. Since $a$ and $b$ are conjugate there exists an $x \! \in \! G$ such that $b = xax^{-1}$. Let $g$ be an arbitrary element of $C_G(a)$. Then,

\begin{align*} (xgx^{-1})(xax^{-1}) &= xgax^{-1}\\
&= xagx^{-1} \tag{since $g \in C_G(a)$}\\
&= (xax^{-1})(xgx^{-1}). \end{align*}

Thus $xgx^{-1} \in C_G(xax^{-1})$. Since $g$ was chosen arbitrarily, $$xC_G(a)x^{-1} \subset C_G(xax^{-1}) = C_G(b).$$ 

Conversely, let $h$ be an arbitary element of $C_G(xax^{-1})$. Then,

\begin{align*} (x^{-1}hx)a &= x^{-1}h(xax^{-1})x \\
&= x^{-1}(xax^{-1})hx \tag{since $h \in C_G(xax^{-1})$} \\
&= a(x^{-1}hx). \end{align*}

So $x^{-1}hx \in C_G(a)$ and since $h$ was arbitrarily chosen from $C_G(xax^{-1})$, \linebreak $x^{-1}C_G(xax^{-1})x \subset C_G(a)$. Multiplication on the left by $x$ and on the right by $x^{-1}$ gives $C_G(b) =  C_G(xax^{-1}) \subset xC_G(a)x^{-1}$. Since we have shown that each set contains the other, $xC_G(a)x^{-1} = C_G(b)$ as required. \\
\end{proof}



\begin{corollary}[ Centralizer of non-central element is commutative]
    \label{IsCommutative_centralizer_of_not_mem_center}
    \uses{SL2_IsConj_d_or_IsConj_s_or_IsConj_neg_s_of_AlgClosed, conjugate_centralizers_of_IsConj, centralizer_s_eq_SZ, centralizer_d_eq_D}
    \lean{IsCommutative_centralizer_of_not_mem_center}
    \leanok
The centraliser of an element $x$ in $\SL_2(F)$ is abelian unless $x$ belongs to the centre of $L$. \vspace{3mm}
\end{corollary}

\begin{proof} This is almost an immediate consequence of the preceding results. Propositions \ref{centralizer_s_eq_SZ} and \ref{centralizer_d_eq_D} show that an element of the form $\pm s_\sigma$ which does not lie in the centre of $\SL_2(F)$ has centraliser $S \times Z$, whilst a non-central element of the form $d_\delta$ has centraliser $D$.
Both $S$ and $D$ are abelian since they are isomoprhic to $F$ and $F^\times$ respectively. Let $s_\sigma z_1$ and $s_\gamma z_2$  be arbitrary elements of $\times Z$.

\vspace{-.5mm}
\begin{align*} 
    (s_\sigma z_1)(s_\gamma z_2)  &= s_\sigma s_\gamma z_2 z_1  \tag{since  $z_1 \in Z$}
\\ &= s_\gamma s_\sigma z_2 z_1  \tag{since  $T$ is abelian}
\\ &= (s_\gamma z_2)(s_\sigma z_1).   \tag{since  $z_2 \in Z$}
\end{align*} 

Thus $S \times Z$ is also abelian. Since every element of $\SL_2(F)$ is conjugate to $d_\delta$ or $\pm s_\sigma$ by Proposition \ref{SL2_IsConj_d_or_IsConj_s_or_IsConj_neg_s_of_AlgClosed} and conjugate elements have conjugate centralisers by Proposition \ref{conjugate_centralizers_of_IsConj}, the centraliser of each $x \in \SL_2(F)\setminus Z$ is conjugate to either $\times Z$ or $D$. 
Proposition \ref{conjugateprop}(iii) shows that conjugate subgroups are isomorphic and therefore have the same structure, thus since both $S \times Z$ and $D$ are abelian, $C_{\SL_2(F)}(x)$ is also abelian. 
Note that in general this does hold for $x \in Z$, since its centraliser is the whole of $\SL_2(F)$which is not abelian unless $\SL_2(F)= Z$.

\end{proof}



\section{The Projective Line \& Triple Transitivity}

It is convenient to sometimes take a geometric viewpoint and regard the elements of $\SL_2(F)$as pairs of vectors in the 2-dimensional vector space over $F$, which we will denote $V$. An element of $\SL_2(F)$is thus a linear transformation of $V$. 

\begin{definition} Let $\mathscr{L}$ be the set of all 1-dimensional subspaces of $V$. A subset $\mathscr{S}$ of $\mathscr{L}$ is called a \textbf{subspace} of $\mathscr{L}$ if there is a subspace $U$ of $V$ such that $\mathscr{S}$ is the set of all 1-dimensional spaces of $U$. We have dim $U =$ dim $\mathscr{S} + 1$. The set $\mathscr{L}$ on which this concept of subspaces is defined is called the \textbf{projective line} on $V$ and an element of $\mathscr{L}$ is a 0-dimensional subspace of $\mathscr{L}$ and consequently called a \textbf{point}. The projective line can be considered as a straight line in the field, plus a point at infinity.
\end{definition}

Any 1-dimensional subspace of $V$ is a set of vectors of the form $\eta u$, where $u$ is a non-zero vector of $V$ and $\eta \in F^\times$. Thus the points of $\mathscr{L}$ are equivalence classes with the following relation defined on the set of vectors of $V$.
\begin{align*} u = \begin{bmatrix} u_1 \\ u_2 \end{bmatrix} \sim \begin{bmatrix} v_1 \\ v_2 \end{bmatrix} = v \iff u = \eta v, \qquad (\text{for $\eta \in F^\times$}).
\end{align*}

Notice that $u$ and $v$ are equivalent if and only if $u_1 v_2 = v_1 u_2$. Importantly each point $P_i$ of $\mathscr{L}$ can be represented by a corresponding equivalence class of vectors of $V$, that is, $P$ corresponds to $u$ if $P = u_1 / u_2$. In the case when $u_2 = 0$, this corresponds to the point at infinity.

\begin{definition} Let $S$ be a permutation group which acts on a set $X$ and $\{ x_1, x_2, x_3 \}$ and $\{ x_1', x_2', x_3' \}$ be two subsets of distinct elements of $X$. Then $S$ is said be \textbf{triply transitive} on $X$ if there is an element $\pi \in S$ such that,
\begin{align*} x^{\pi}_i = x'_i, \qquad(\text{$i$ = 1,2 or 3}).
\end{align*} 
\end{definition}

\begin{theorem} \label{6.6}
Let $\mathscr{L}$ be the projective line over the field $F$. Then $\SL_2(F)$is triply transitive on the set of the points of $\mathscr{L}$. \vspace{3mm}
\end{theorem}

\begin{proof} Let $P_1$, $P_2$ and $P_3$ be distinct points of $\mathscr{L}$ and $p_i$ be a vector in $V$ corresponding to $P_i$. Since each $P_i$ is distinct, $p_1$, $p_2$ and $p_3$ are thus pairwise linearly independent. Thus $p_1$ and $p_2$  form a basis for $V$ and it's clear that there exist $\alpha, \beta \in F^\times$ such that,
\begin{align*} p_3 = \alpha p_1 + \beta p_2.
\end{align*}

Now, let $Q_1$, $Q_2$ and $Q_3$ be three more distinct points of $\mathscr{L}$ and $q_i$ be a vector in $V$ corresponding to $Q_i$. Similarly, by the above argument, there exist $\gamma, \delta \in F^\times$ such that,
\begin{align*} q_3 = \gamma q_1 + \delta q_2.
\end{align*}

Let $\pi \in GL(2,F)$ be the linear transformation which sends $\alpha p_1$ to $\gamma q_1$  and $\beta p_2$ to $\delta q_2$. Thus,
\begin{align*} \pi(p_3) = \pi(\alpha p_1 + \beta p_2) = \pi(\alpha p_1) + \pi(\beta p_2) = \gamma q_1 + \delta q_2 = q_3 
\end{align*}

Hence we get $P^\pi_1 = Q_1$, $P^\pi_2 = Q_2$ and $P^\pi_3 = Q_3$ and $GL(2,F)$ is triply transitive. Now set,
\begin{align*} \eta = \sqrt{\frac{1}{\text{det }\pi}}.
\end{align*}

Consider the mapping $\theta$ which sends $\alpha p_1$ to $\eta \gamma q_1$ and $\beta p_2$ to $\eta \delta q_2$. Observe that,
\begin{align*} \text{det }\theta = \eta^2 \, \text{det } \pi = 1
\end{align*}

So $\theta \in SL(2,F) = \SL_2(F)$and since $P^\theta_1 = Q_1$, $P^\theta_2 = Q_2$ and $P^\theta_3 = Q_3$, we have that $\SL_2(F)$is also triply transitive. 

\end{proof}

The following proposition looks at what happens when the group $\SL_2(F)$acts on the projective line $\mathscr{L}$.

\begin{proposition} \label{6.7} (i) Each element of the form $d_\delta$ (with $\delta \neq \pm 1$), fixes the same two points on the projective line $\mathscr{L}$ and fix no other point. \vspace{3mm} \\
(ii) Each element of the form $\pm s_\sigma$ (with $\sigma \neq 0$), fixes the same point $P$ on $\mathscr{L}$ and fix no other point. Furthermore, \emph{Stab}$(P) = H$. \vspace{3mm} \\
(iii) All conjugate elements have the same number of fixed points on $\mathscr{L}$. \vspace{3mm} \\
(iv) Any noncentral element of $\SL_2(F)$has at most 2 fixed points on $\mathscr{L}$.
\end{proposition}

\begin{proof} 
(i) Let $P$ be a fixed a point of an arbitrary $d_\delta \in D$, with $\delta \neq \pm 1$ and let $u$ belong to the corresponding equivalence class of vectors of $V$ to $P$. \\
\begin{align*} d_\delta u = \begin{bmatrix} \delta & 0 \\ 0 & \delta^{-1} \end{bmatrix} \begin{bmatrix} u_1 \\ u_2 \end{bmatrix} &= \begin{bmatrix} u_1 \delta \\ u_2 \delta^{-1} \end{bmatrix} \sim \begin{bmatrix} u_1 \\ u_2 \end{bmatrix}, 
\\[1.5ex] u_1 u_2 \delta &= u_1 u_2 \delta^{-1}.
\end{align*}

Since $\delta \neq \pm 1$, $\delta$ does not equal $\delta^{-1}$, and so either $u_1 = 0$ or $u_2 = 0$. Thus $u$ is equivalent to either the vector $\begin{bmatrix} 0 \\ 1 \end{bmatrix}$ or $\begin{bmatrix} 1 \\ 0 \end{bmatrix}$ and these correspond to 2 distinct points of $\mathscr{L}$ which are fixed by $d_\delta$. \\
\\
(ii) Let $P$ be a fixed a point of an arbitrary $s_\sigma$, with $\sigma \neq 0$, and let $u$ be the corresponding element of $V$ to $P$. \\
\begin{align*} s_\sigma u = \begin{bmatrix} 1 & 0 \\ \sigma & 1 \end{bmatrix} \begin{bmatrix} u_1 \\ u_2 \end{bmatrix} &= \begin{bmatrix} u_1 \\ u_1 \sigma + u_2 \end{bmatrix} \sim \begin{bmatrix} u_1 \\ u_2 \end{bmatrix}, 
\\[1.5ex] u_1 u_2 &= {u_1}^2 \sigma + u_1 u_2.
\end{align*}

This gives ${u_1}^2 \sigma = 0$ and since $\sigma \neq 0$ we have $u_1 = 0$. Thus $s_\sigma$ has just one fixed point, $P$ which corresponds to the equivalence class of $\begin{bmatrix} 0 \\ 1 \end{bmatrix}$ in $V$. We show also that $P$ is also the only fixed point of $-s_\sigma$, with $\sigma \neq 0$.
\begin{align*} -s_\sigma u = \begin{bmatrix} -1 & 0 \\ \sigma & -1 \end{bmatrix} \begin{bmatrix} u_1 \\ u_2 \end{bmatrix} &= \begin{bmatrix} -u_1 \\ u_1 \sigma - u_2 \end{bmatrix} \sim \begin{bmatrix} u_1 \\ u_2 \end{bmatrix}, 
\\[1.5ex] -u_1 u_2 &= {u_1}^2 \sigma - u_1 u_2.
\end{align*}

So again $u_1 =0$ and $-s_\sigma$ fixes $P$ and no other point. We now calculate the stabiliser of $P$ in $L$, by considering which $x \in \SL_2(F)$fix $P$. \\
\begin{align*} x u = \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix} \begin{bmatrix} 0 \\ 1 \end{bmatrix} &= \begin{bmatrix} \beta \\ \delta \end{bmatrix} \sim \begin{bmatrix} 0 \\ 1 \end{bmatrix}.
\end{align*}

Thus $\beta = 0$ and $x \in H$. Since $x$ was chosen arbitrarily from Stab$(P)$, we have Stab$(P) \subset H$. Now let an arbitrarily chosen $y \in H$ act on $P$. \\
\begin{align*} y u = \begin{bmatrix} \alpha & 0 \\ \gamma & \alpha^{-1} \end{bmatrix} \begin{bmatrix} 0 \\ 1 \end{bmatrix} &= \begin{bmatrix} 0 \\ \alpha^{-1} \end{bmatrix} \sim \begin{bmatrix} 0 \\ 1 \end{bmatrix}.
\end{align*}

Thus $y$ and indeed $H$ is contained in Stab$(P)$, so Stab$(P) = H$ as desired. \\
\\
(iii) Let $P_i$ $(i = 1,2,...)$ be the fixed points of $x\in \SL_2(F)$and let $y$ be conjugate to $x$ in $L$. That is, there exists a $g \in \SL_2(F)$such that $x = gyg^{-1}$.
\begin{align*} x P_i &= P_i,
\\ gyg^{-1} P_i &= P_i,
\\ y(g^{-1} P_i) &= (g^{-1} P_i).
\end{align*}

This shows that $P_i$ is a fixed point of $x$ if and only if $g^{-1} P_i$ is a fixed point of $y$. Thus conjugate elements have the same number of fixed points. \\
\\
(iv) By Proposition \ref{6.3}(i), every  element of $\SL_2(F)$is conjugate to either $d_\delta$ or $\pm s_\sigma$, so since conjugate elements have the same number of fixed points, every element of $\SL_2(F)\! \setminus \! Z$ has either the same number of fixed points as $d_\delta$ (with $\delta \neq \pm 1$), namely 2, or the same number as $\pm s_\sigma$, (with $\sigma \neq 0$), namely 1.

\end{proof}


